---
title: "Heart Disease Project"
author: "Andrew Brown; Sebastian Negrete"
date: "April 30, 2019"
output: html_document
---

#**Table of Contents**
  1. [Note From the Authors](#Note)
  
  2. [Introduction](#Intro)
  
    A. [Data Acquisition](#DA)
    
    B. [Data Description](#DD)
    
  3. [EDA](#EDA)
  
    A. [General Prominent Features](#GPF)
    
    B. [Interesting Discoveries](#ID)
    
      i. [Age Histogram](#I)
      
      ii. [Histograms of Other Variables' Distributions](#II)
      
      iii. [Simple KMeans](#III)
      
      iv. [Multi-variable KMeans](#IV)
      
      v. [DBSCAN](#V)
      
      vi. [Gaussian Mixture](#VI)
  
  4. [Problem Specification](#PS)
  
  5. [Machine Learning Solution](#MLS)
  
    A. [Logistical Regression](#LR)
    
    B. [SVM](#SVM)
    
    C. [Random Forest](#RF)
    
    D. [PCA](#PCA)
  
  6. [Performance and Analysis](#PA)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## <a name="Note"></a>**Note From the Authors**
  This report was created by Andrew Brown and Sebastian Negrete for a data science class at MidAmerica Nazarene University in the Spring semester of 2019; the final product was edited by both of us, but the primary authors of each section are as follows: Introduction-Andrew, EDA-Andrew, Problem Specification-Andrew, Machine Learning Solution-Sebastian, and Performance and Analysis-Sebastian.


## <a name="Intro"></a>**Introduction**

### <a name="DA"></a>Data Acquisition
  The dataset used in this report originates from a collection of medical patient data posted on UCI's machine learning repository: https://archive.ics.uci.edu/ml/datasets/Heart+Disease. The credit of acquiring the raw data goes to Andras Janosi, M.D. of Hungarian Institute of Cardiology in Budapest, William Steinbrunn, M.D. of University Hospital in Zurich, Switzerland, Matthias Pfisterer, M.D. of University Hospital in Basel, Switzerland, and Robert Detrano, M.D., Ph.D. of V.A. Medical Center in Long Beach and of Cleveland Clinic Foundation.
  A portion of the dataset was uploaded to Kaggle by a user under the name ronit: https://www.kaggle.com/ronitf/heart-disease-uci. This Kaggle page is where the dataset used in this report was downloaded from.


### <a name="DD"></a>Data Description
The dataset has 303 observations, each representing a patient, and it has 14 parameters. Below is an explanation of each parameter.

Age: The patient's age given in years.

Sex: The patient's sex. 1 indicates male and 0 indicates female.

Cp: The patient's chest pain type. 0 represents typical angina, 1 represents atypical angina, 2 represents non-anginal pain, and 3 represents asymptomatic.

Trestbps: The patient's resting blood pressure upon admission to the hospital (measured in mm Hg).

Chol: The patient's serum cholesterol in mg/dl.

Fbs: The patient's fasting blood sugar. 1 represents a value greater than 120 mg/dl and 0 represents a value less than or equal to 120 mg/dl.

Restecg: The patient's resting electrocardiographic results. 0 represents normal, 1 represents having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of  > 0.05 mV), 2 represents showing probable or definite left ventricular hypertrophy by Estes' criteria.

Thalach: The maximum heart rate achieved by the patient in bpm.

Exang: Whether or not the patient has exercise induced chest pain. 1 means yes and 0 means no.

Oldpeak: The patient's ST depression induced by exercise, relative to rest. ST depression refers to a finding on an electrocardiogram, wherein the trace in the ST segment is abnormally low below the baseline.

Slope: The slope of the peak exercise ST segment. 0 means upsloping, 1 means flat, and 2 means down sloping.

Ca: The number of the patient's major vessels colored by fluoroscopy. The web site with the original data set said that this number would be between 0-3, but a few 4's appeared. We decided to assume that the 4's simply represented 4 major vessels colored by fluoroscopy so no editing of the data was necessary on this parameter.

Thal: 1 represents normal, 2 represents fixed defect, and 3 represents reversable defect. The web site did not specify what a 0 would represent, but two 0's were found in the data set, so we decided to remove these two rows to be safe.

Target: Whether or not the patient has heart disease. Determined by: angiographic disease status, 0 means < 50% diameter narrowing, 1 means > 50% diameter narrowing.


## <a name="EDA"></a>**EDA**
```{r loadData, include=FALSE, echo=FALSE}
#R project 3: Heart Disease, by Andrew Brown and Sebastian Negrete. April 2019

require(ROCR)
require(stringr)
require(dbscan)
require(ClusterR)
require(e1071)
require(randomForest)

hdf <- read.csv("heart.csv")
names(hdf)[1] <- "age"
hdf <- hdf[-c(49, 282),]
#hdf will be the copy used for EDA, but hf will be used for machine learning
hf <- as.matrix(read.csv("heart.csv"))
hf <- as.data.frame(hf)
hf <- hf[-c(49, 282),]

set.seed(2681678)
```


### <a name="GPF"></a>General Prominent Features
  This section constitutes the Exploratory Data Analysis (EDA) I performed on this dataset. I used several different methods of EDA, and I will show a few of my significant findings in the section below entitled Interesting Discoveries.
  At a general glance, all the variables are pretty independent of each other. There wasn't a lot of correlation to find in terms of one or more variables being able to indicate another variable. This means that between the 14 parameters there is a lot of information in this dataset.


### <a name="ID"></a>Interesting Discoveries

#### <a name="I"></a>*Age Histogram*
This graph is a histogram for the number of patient's in each age group who have heart disease. This graph has some similarities to a normal distribution, except for a couple low points for patients in their late forties and early sixties.

```{r i, echo=FALSE}
#1 Age Histogram
#Shows distribution of people's age who have heart disease
hist(hdf$age[hdf$target==1], breaks=49, xlab="Age", main="Distriubtion of patient's ages who have heart disease", col="red")
#This graph shows a distribution of all the people's age in our data set
#hist(hdf$age, breaks=49)
```


#### <a name="II"></a>*Histograms of Other Variables' Distributions*
These next four graphs are histograms, each for a different parameter. The x-axes of the graphs are different values for the graph's parameter, and the y-axis shows how many patients in the dataset have that level of the parameter. I chose these four graphs because they had the most interesting distributions for the patients in the dataset.

```{r ii, echo=FALSE}
#2 Histograms of normalish distributions
#These graphs show the distributions of certain parameters to see how the data collected was. Like if it was a normal distribution or not.
hist(hdf$trestbps, breaks=27, xlab="Trestbps", main="Distriubtion of patient's resting blood pressure in the dataset", col="green") #107
hist(hdf$chol, breaks=50, xlab="Chol", main="Distriubtion of patient's cholesteral in the dataset", col="green")
hist(hdf$thalach, breaks=66, xlab="Thalach", main="Distriubtion of patient's max heart rate in the dataset", col="green")
hist(hdf$oldpeak, breaks=24, xlab="Oldpeak", main="Distriubtion of patient's ST depression in the dataset", col="green")
```


#### <a name="III"></a>*Simple KMeans*
This graph is a representation of a kmeans clustering I performed to break the patients into 3 groups based on Age and Oldpeak. A kmeans clusters data into different groups based on how close the data points are to each other geometrically. This graph is a kmeans based off just 2 parameters, so the separation can be seen easily.

```{r iii, echo=FALSE}
#3 Simple Kmeans
kmclusters <- kmeans(hdf[,c(1,10)], centers=3)
hdf$km <- kmclusters$cluster
plot(hdf$age, hdf$oldpeak, col=hdf$km, xlab="Age", ylab="Oldpeak", main="A graph of a 2-dimensional KMeans clustering")
legend("topleft", legend = "Each color is a different group", cex = .9)
```


#### <a name="IV"></a>*Multi-variable KMeans*
These next three graphs are each a 2-dimensional representation of a Kmeans built of four different parameters. Since the Kmeans clustered the four different groups based off of a 4-dimensional geometric hyperspace, it can be difficult to represent this with a graph. So, I created three different 2-dimensional representations of the same Kmeans clustering. The second graph shows the separation the best, indicating that Age and Chol were the two most important variables when determining the clustering.

```{r iv, echo=FALSE}
#4 Multi-variable Kmeans (Note that the graphs only let us look at 2 at a time, but if it was a 4-dimensional graph you could see all the groups easily)
kmclusters <- kmeans(hdf[,c(1,4,5,8)], centers=4)
hdf$km <- kmclusters$cluster
plot(hdf$age, hdf$trestbps, col=hdf$km, xlab="Age", ylab="Trestbps", main="A multi-dimensional KMeans graphed in 2 dimensions")
legend("topleft", legend = "Each color is a different group", cex = .9)
plot(hdf$age, hdf$chol, col=hdf$km, xlab="Age", ylab="Chol", main="A multi-dimensional KMeans graphed in 2 dimensions")
legend("topleft", legend = "Each color is a different group", cex = .9)
plot(hdf$age, hdf$thalach, col=hdf$km, xlab="Age", ylab="Thalach", main="A multi-dimensional KMeans graphed in 2 dimensions")
legend("bottomleft", legend = "Each color is a different group", cex = .9)
```


#### <a name="V"></a>*DBSCAN*
This graph is representation of a density-based spatial clustering of applications with noise (DBSCAN). I used DBSCAN clustering with the two parameters Trestbps and Oldpeak. DBSCAN works by clustering points together that are within a certain distance of each other; this distance is represented by an epsilon value. One advantage of this clustering method is that it eliminates outliers by not clustering groups if they don't have a base number of points near them. The long shapes of the clusters in the graph below show that for many of the different Trestbps values patients still have very diverse Oldpeak values.

```{r v, echo=FALSE}
#5 DBSCAN
DB <- dbscan(hdf[,c(4,10)], eps = 1.9, minPts = 5)
hdf$db <- DB$cluster
plot(hdf$trestbps, hdf$oldpeak, col=hdf$db, xlab="Trestbps", ylab="Oldpeak", main="A graph of a DB Scan clustering")
legend("topright", legend = "Each color is a different group", cex = .9)

```


#### <a name="VI"></a>*Gaussian Mixture*
This last graph is a representation of a Gaussian Mixture clustering. A Gaussian Mixture is used for data that has a normal distribution, so I used this clustering method on Chol and Thalach because they have some of the most normal distributions of all the parameters in the dataset. The graph shows the two different groups, the red group is the patients who are close to the mean, and the black group is the patients who aren't close to the mean.

```{r vi, echo=FALSE}
#6 Gaussian Mixture
gmm <- GMM(hdf[,c(5,8)], 1)
hdf$gm <- gmm$Log_likelihood
plot(hdf$chol, hdf$thalach, col=(as.integer(hdf$gm>mean(hdf$gm))+1), xlab="Chol", ylab="Thalach", main="A graph of a Gaussian Mixture clustering")
legend("bottomright", legend = "Each color is a different group", cex = .9)
```


## <a name="PS"></a>**Problem Specification**
The goal of the rest of this report is to create a machine learning model that can predict whether or not a patient has heart disease based on the first 13 parameters in the dataset. This is the reason that the final parameter column is called "target". The machine learning models are trained to be able to predict the value (0 or 1) of the target column. Machine learning models that are very good at this would be extremely valuable in the medical field. This is because it would provide a cheaper means of determining a patient's risk of heart disease, and the models could be run on millions of patients very quickly with computers.


## <a name="MLS"></a>**Machine Learning Solution**

### <a name="LR"></a>Logistical Regression
Logistic Regression is used for both classifying and regression. The first thing that needed to happen was to retrieve the csv file by using read.csv. Then a training and testing model were created by making a new column of random numbers from 1-5. A fifth of the data set would be testing and the rest would be training. The for loop was used to initialize the train and test variables. At the same time the model was created along with adding a predicition column. After that the ROC AUC of the model and the training was created for compaison to tell whether or not the model is overfit.

```{r Logistical Regression, echo=FALSE}
hf$group <- sample(1:5, nrow(hf), replace = TRUE)
modeling_variables <- c("ï..age", "sex", "trestbps", "thal", "chol", "oldpeak", "exang", "thalach", "cp")
for (group in 1:5){
  train <- hf[hf$group != group, c(modeling_variables, "target")]
  test <- hf[hf$group == group, modeling_variables]
  model <- glm(target ~ ., family = binomial(link = 'logit'), data = train)
  hf$prediction[hf$group == group] <- predict(model, test)
  train$prediction <- predict(model, train)
}
pr <- ROCR::prediction(train$prediction, train$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Training ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Training ROC AUC: ",auc))
pr <- ROCR::prediction(hf$prediction, hf$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Test ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Model ROC AUC: ", auc))
```


### <a name="SVM"></a>SVM
SVM is used for classification by using a hyperplane to seperate the two groups. The model in svm is different because it can change the function, kernel, used in the model. In our dataset the sigmoid kernel was best for our question we were asking.

```{r SVM,echo=TRUE}
modeling_variables <- c("ï..age", "sex", "cp", "oldpeak", "trestbps", "thal", "fbs", "ca", "exang")
for (group in 1:5){
  train <- hf[hf$group != group, c(modeling_variables, "target")]
  test <- hf[hf$group == group, modeling_variables]
  model <- svm(target ~ ., train, cost = 0.1, tolerance = 0.01, kernel='sigmoid')
  hf$prediction[hf$group == group] <- predict(model, test)
  train$prediction <- predict(model, train)
}
pr <- ROCR::prediction(train$prediction, train$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Training ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Training ROC AUC: ",auc))
pr <- ROCR::prediction(hf$prediction, hf$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Test ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Model ROC AUC: ", auc))
```


### <a name="RF"></a>Random Forest
Random forest algorithm can be used for both classifications and regression task. In the tree algorithm, only a singular tree was created for the model, but using the random forest model helped create more trees that fixed the overfitting problem. This process is called bagging. Also, we can increae the mtry and nodesize variables to decrease overfitting.

```{r Random Forest, echo=TRUE, warning=FALSE}
modeling_variables <- c("ï..age", "sex", "cp", "oldpeak", "trestbps", "thal", "fbs", "ca", "slope")
for (group in 1:5){
  train <- hf[hf$group != group, c(modeling_variables, "target")]
  test <- hf[hf$group == group, modeling_variables]
  model <- randomForest(target~., train, ntrees = 5000, mtry = 2000, nodesize = 250, maxnodes = 5)
  hf$prediction[hf$group == group] <- predict(model, test)
  train$prediction <- predict(model, train)
}
pr <- ROCR::prediction(train$prediction, train$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Training ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Training ROC AUC: ",auc))
pr <- ROCR::prediction(hf$prediction, hf$target)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf, main = "Test ROC curve")
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
print(paste("Test ROC AUC: ", auc))
```


### <a name="PCA"></a>PCA
The first two columns of the plot are PC1 and PC2 which is the most important. It is new varialbe that is a linear combination of the other variables.

```{r PCA, echo=TRUE}
hf.pca <- prcomp(hf)
hf.rotated <- as.data.frame(hf.pca$x)
hf.vectors <- as.data.frame(hf.pca$rotation)

barplot(hf.pca$sdev, xlab = "PC1-PC14")
```


## <a name="PA"></a>**Performance and Analysis**
The first machine learning algorithm that was used was logistical regression. The reason for this is because that this type of regression is great for classification. The goal for this data set was to classify whether or not someone had heart disease. Yes would be 1, and No would be 0 in the target column in the heart data set. Since the logistical regression algorithm uses the sigmoid equation from 0-1 in the y axis, respones variable, it would be best for finding our answer of whether or not someone has heart disease. The second option for a machine learning algoithm is SVM. SVM is also a great classifier algorithm. For the SVM model, it finds the best separating hyperplane from the types of point (1's and 0's). These hyperplanes can vary depending on the kernel type. In this case, the sigmoid kernel was used since the answer is either 1 or 0. This created a model that was not too over fit or too under fit. Other functions included in kernel are polynomial, linear, and radical basis. The decision tree algorithm was the third machine learning model used for this data set. Using the randomforest model was better than trees because it prevented a large amout of overfitting. This is because of the bagging process which uses not one but multiple trees. Though, this model did overfit a little, it still provided a profficient ROC AUC. The best model out of the three was the SVM model. It provided a ROC AUC of 0.8824105 with a training model ROC AUC of 0.8953279. This modle was not too under fit or too over fit, so this is a great model for this data set.

